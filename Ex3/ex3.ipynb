{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Conjunto de treinamento\n",
    "training_data = [\n",
    "    ([-0.6508, 0.1097, 4.0009], -1),\n",
    "    ([-1.4492, 0.8896, 4.4005], -1),\n",
    "    ([2.085, 0.6876, 12.071], -1),\n",
    "    ([0.2626, 1.1476, 7.7985], 1),\n",
    "    ([0.6418, 1.0234, 7.0427], 1),\n",
    "    ([0.2569, 0.673, 8.3265], -1),\n",
    "    ([1.1155, 0.6043, 7.4446], 1),\n",
    "    ([0.0914, 0.3399, 7.0677], -1),\n",
    "    ([0.0121, 0.5256, 4.6316], 1),\n",
    "    ([-0.0429, 0.466, 5.4323], 1),\n",
    "    ([0.434, 0.687, 8.2287], -1),\n",
    "    ([0.2735, 1.0287, 7.1934], 1),\n",
    "    ([0.4839, 0.4851, 7.485], -1),\n",
    "    ([0.4089, -0.1267, 5.5019], -1),\n",
    "    ([1.4391, 0.1614, 8.5843], -1),\n",
    "    ([-0.9115, -0.1973, 2.1962], -1),\n",
    "    ([0.3654, 1.0475, 7.4858], 1),\n",
    "    ([0.2144, 0.7515, 7.1699], 1),\n",
    "    ([0.2013, 1.0014, 6.5489], 1),\n",
    "    ([0.6483, 0.2183, 5.8991], 1),\n",
    "    ([-0.1147, 0.2242, 7.2435], -1),\n",
    "    ([-0.797, 0.8795, 3.8762], 1),\n",
    "    ([-1.0625, 0.6366, 2.4707], 1),\n",
    "    ([0.5307, 0.1285, 5.6883], 1),\n",
    "    ([-1.22, 0.7777, 1.7252], 1),\n",
    "    ([0.3957, 0.1076, 5.6623], -1),\n",
    "    ([-0.1013, 0.5989, 7.1812], -1),\n",
    "    ([2.4482, 0.9455, 11.2095], 1),\n",
    "    ([2.0149, 0.6192, 10.9263], -1),\n",
    "    ([0.2012, 0.2611, 5.4631], 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número máximo de iterações (épocas)\n",
    "max_iterations = 100\n",
    "\n",
    "def initialize_weights():\n",
    "    #Inicialização de pesos aleatórios entre 0 e 1 conforme solicitado \n",
    "    return [random.uniform(0, 1) for _ in range(3)]\n",
    "\n",
    "def update_weights(weights, input_vector, target, learning_rate):\n",
    "    #Cálculo da saída do perceptron\n",
    "    output = sum([x * w for x, w in zip(input_vector, weights)])\n",
    "    \n",
    "    #Atualização dos pesos (Saída desejada - saída obtida)\n",
    "    error = target - output\n",
    "    weights = [w + learning_rate * error * x for x, w in zip(input_vector, weights)]\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos finais para o primeiro treinamento: [0.5557114454556583, 2.2144718257715112, -0.2231477207273519]\n",
      "Pesos finais para o segundo treinamento: [0.564316118581258, 2.2455487167291333, -0.22571845345625763]\n"
     ]
    }
   ],
   "source": [
    "def train_perceptron(training_data, max_iterations, learning_rate):\n",
    "    #Inicialização dos pesos para o primeiro treinamento\n",
    "    weights_1 = initialize_weights()\n",
    "    \n",
    "    #Inicialização dos pesos para o segundo treinamento\n",
    "    weights_2 = initialize_weights()\n",
    "    \n",
    "    epochs_1 = 0\n",
    "    epochs_2 = 0\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        #Treinamento com o primeiro conjunto de pesos\n",
    "        for input_vector, target in training_data:\n",
    "            weights_1 = update_weights(weights_1, input_vector, target, learning_rate)\n",
    "        \n",
    "        epochs_1 += 1\n",
    "        \n",
    "        #Verifica se os perceptrons convergiram (classificaram corretamente todos os exemplos)\n",
    "        if all([sum([x * w for x, w in zip(input_vector, weights_1)]) == target for input_vector, target in training_data]):\n",
    "            break\n",
    "        \n",
    "    for i in range(max_iterations):\n",
    "        #Treinamento com o segundo conjunto de pesos\n",
    "        for input_vector, target in training_data:\n",
    "            weights_2 = update_weights(weights_2, input_vector, target, learning_rate)\n",
    "        \n",
    "        epochs_2 += 1\n",
    "        \n",
    "        #Verificando se as classificações foram corretas (se convergiram o erro para 0)\n",
    "        if all([sum([x * w for x, w in zip(input_vector, weights_2)]) == target for input_vector, target in training_data]):\n",
    "            break\n",
    "    \n",
    "    return weights_1, weights_2, epochs_1, epochs_2\n",
    "\n",
    "#Treinamento com uma taxa de aprendizado reduzida de 0.01 (a não redução estava causando problemas nos ajustes dos pesos)\n",
    "weights_1, weights_2, epochs_1, epochs_2 = train_perceptron(training_data, max_iterations, 0.01)\n",
    "\n",
    "#Pesos obtidos para os treinamentos\n",
    "print(\"Pesos finais para o primeiro treinamento:\", weights_1)\n",
    "print(\"Pesos finais para o segundo treinamento:\", weights_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabela de Resultados de Teste:\n",
      "Amostra    x1         x2         x3         y (T1)    \n",
      "1          -0.3565    0.062      5.9891     -1         -1        \n",
      "2          -0.7842    1.1267     5.5912     1          1         \n",
      "3          0.3012     0.5611     5.8234     1          1         \n",
      "4          0.7757     1.0648     8.0677     1          1         \n",
      "5          0.157      0.8028     6.304      1          1         \n",
      "6          -0.7014    1.0316     3.6005     1          1         \n",
      "7          0.3748     0.1536     6.1537     -1         -1        \n",
      "8          -0.692     0.9404     4.4058     1          1         \n",
      "9          -1.397     0.7141     4.9263     -1         -1        \n",
      "10         -1.8842    -0.2805    1.2548     -1         -1        \n"
     ]
    }
   ],
   "source": [
    "#Conjunto de testes\n",
    "test_data = [\n",
    "    [-0.3565, 0.0620, 5.9891],\n",
    "    [-0.7842, 1.1267, 5.5912],\n",
    "    [0.3012, 0.5611, 5.8234],\n",
    "    [0.7757, 1.0648, 8.0677],\n",
    "    [0.1570, 0.8028, 6.3040],\n",
    "    [-0.7014, 1.0316, 3.6005],\n",
    "    [0.3748, 0.1536, 6.1537],\n",
    "    [-0.6920, 0.9404, 4.4058],\n",
    "    [-1.3970, 0.7141, 4.9263],\n",
    "    [-1.8842, -0.2805, 1.2548]\n",
    "]\n",
    "\n",
    "#Função classificadora\n",
    "def classify_sample(input_vector, weights):\n",
    "    output = sum([x * w for x, w in zip(input_vector, weights)])\n",
    "    return 1 if output > 0 else -1\n",
    "\n",
    "#Resultados da classificação para cada amostra usando os pesos de T1 e T2\n",
    "results_T1 = [classify_sample(sample, weights_1) for sample in test_data]\n",
    "results_T2 = [classify_sample(sample, weights_2) for sample in test_data]\n",
    "\n",
    "#Tabela de Resultados após classificação do conjunto de testes \n",
    "print(\"\\nTabela de Resultados de Teste:\")\n",
    "print(\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format(\"Amostra\", \"x1\", \"x2\", \"x3\", \"y (T1)\", \"y (T2)\"))\n",
    "for i in range(len(test_data)):\n",
    "    print(\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(i+1, test_data[i][0], test_data[i][1], test_data[i][2], results_T1[i], results_T2[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
